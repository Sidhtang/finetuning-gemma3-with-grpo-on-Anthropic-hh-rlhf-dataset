{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "766fedca6b4b4e7184ce9ce192eb653d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d8ab1b8ce6c49578f1fed99b92c9db1",
              "IPY_MODEL_8a85258aee9340e59c2c85fa56fe35da",
              "IPY_MODEL_800782a9209c4b1ab8b9b6ff83004138"
            ],
            "layout": "IPY_MODEL_63659db7558044dbbf84d67c92a71f56"
          }
        },
        "3d8ab1b8ce6c49578f1fed99b92c9db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2e93ac871b34fdba871f7d4999a3109",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab3687fceef4406aaa5d1f6fde266da",
            "value": "Fetching 2 files: 100%"
          }
        },
        "8a85258aee9340e59c2c85fa56fe35da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c518209bff49758db5755a71920b63",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_080563fa493b4156a0d015d2c39dac02",
            "value": 2
          }
        },
        "800782a9209c4b1ab8b9b6ff83004138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd52bcb5b02d482ca90cff90a15f512f",
            "placeholder": "​",
            "style": "IPY_MODEL_2330899f0d6b4dc2b685b22a85b46893",
            "value": " 2/2 [00:00&lt;00:00, 153.86it/s]"
          }
        },
        "63659db7558044dbbf84d67c92a71f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e93ac871b34fdba871f7d4999a3109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab3687fceef4406aaa5d1f6fde266da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88c518209bff49758db5755a71920b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "080563fa493b4156a0d015d2c39dac02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd52bcb5b02d482ca90cff90a15f512f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2330899f0d6b4dc2b685b22a85b46893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b901ba7bf4e34ef2bfe40aa0d9acf3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64876cba3c7a4e118501a937a667da06",
              "IPY_MODEL_af64ce1d2b2349be9485c5b6b90c3a43",
              "IPY_MODEL_d46c51d2360344978f2b3240a14aa2ba"
            ],
            "layout": "IPY_MODEL_fa396d33890b4570a0fffe23838c70cd"
          }
        },
        "64876cba3c7a4e118501a937a667da06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b70dcc0f18d441ab310fc2d22a402f9",
            "placeholder": "​",
            "style": "IPY_MODEL_a02b009722d74b2b97623008d798a72b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "af64ce1d2b2349be9485c5b6b90c3a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbb4dd5cd654f75a04b28f834d94405",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_399988f4b67b4cb08f8518be01865269",
            "value": 2
          }
        },
        "d46c51d2360344978f2b3240a14aa2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b9eac714044a89b1e0f1402b0943fb",
            "placeholder": "​",
            "style": "IPY_MODEL_47165f1bca024a02ba5e197ec2b848c0",
            "value": " 2/2 [00:35&lt;00:00, 17.78s/it]"
          }
        },
        "fa396d33890b4570a0fffe23838c70cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b70dcc0f18d441ab310fc2d22a402f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02b009722d74b2b97623008d798a72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adbb4dd5cd654f75a04b28f834d94405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399988f4b67b4cb08f8518be01865269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8b9eac714044a89b1e0f1402b0943fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47165f1bca024a02ba5e197ec2b848c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f126918abe94475b17482f5979c151e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5de759dd94a949d5b4de0fa4e318b7f8",
              "IPY_MODEL_e7a7145f47ae48489f4ea0281fd8370d",
              "IPY_MODEL_c7657116946b4feab964896704523ad6"
            ],
            "layout": "IPY_MODEL_5a5077c05612429d9e900f932d4ca9ed"
          }
        },
        "5de759dd94a949d5b4de0fa4e318b7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03aa0a1c8fe4dfbb1da56ba3c8ca620",
            "placeholder": "​",
            "style": "IPY_MODEL_196f450b6ae44690b6650a1cb7651279",
            "value": "Fetching 2 files: 100%"
          }
        },
        "e7a7145f47ae48489f4ea0281fd8370d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b0a692a272458b9f36f195f69e8efa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_268ed8209ce04c199db8f16ca439090a",
            "value": 2
          }
        },
        "c7657116946b4feab964896704523ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aebc34c41e71481cbbfe53f22d53da9e",
            "placeholder": "​",
            "style": "IPY_MODEL_dabe169814364576b871babea2285fcd",
            "value": " 2/2 [00:00&lt;00:00, 186.26it/s]"
          }
        },
        "5a5077c05612429d9e900f932d4ca9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03aa0a1c8fe4dfbb1da56ba3c8ca620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196f450b6ae44690b6650a1cb7651279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b0a692a272458b9f36f195f69e8efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268ed8209ce04c199db8f16ca439090a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aebc34c41e71481cbbfe53f22d53da9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabe169814364576b871babea2285fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf6c3d7c9ae4e13a8c1b8a74c9bef62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a2821ef8d8543efa9459f3c1c09017d",
              "IPY_MODEL_96671afcb6f740c4be322560ae65d6d7",
              "IPY_MODEL_2da7dc119d9a426793bf040c6b691270"
            ],
            "layout": "IPY_MODEL_96a4427cfaf34cf3930bbc2e0dfc43eb"
          }
        },
        "1a2821ef8d8543efa9459f3c1c09017d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc96d16c5d14bf494f02c6610cf5d4b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c29df1d62a0448e9f544364bef0087f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "96671afcb6f740c4be322560ae65d6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55cf9024f5f4874977b2124d47f81c8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c56f9532299b4cdcb990dc93ee046958",
            "value": 2
          }
        },
        "2da7dc119d9a426793bf040c6b691270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a356641c274412bb455dbc82f82f1fc",
            "placeholder": "​",
            "style": "IPY_MODEL_2ace1e39a8f54648bd0091c5377c9a82",
            "value": " 2/2 [00:25&lt;00:00, 11.62s/it]"
          }
        },
        "96a4427cfaf34cf3930bbc2e0dfc43eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc96d16c5d14bf494f02c6610cf5d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c29df1d62a0448e9f544364bef0087f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e55cf9024f5f4874977b2124d47f81c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56f9532299b4cdcb990dc93ee046958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a356641c274412bb455dbc82f82f1fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ace1e39a8f54648bd0091c5377c9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd9487d0509414a9557c94315066299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f87e5eac4fc475489c7bc3f2ac8a930",
              "IPY_MODEL_7bc3b8b86ca54eb59f66ae94d23fa186",
              "IPY_MODEL_0a03827db76446bfb36bc70849803340"
            ],
            "layout": "IPY_MODEL_613ec92d95344923bd7242d8ad903360"
          }
        },
        "4f87e5eac4fc475489c7bc3f2ac8a930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a84961a1d694c8597ddb6dbe0dddb89",
            "placeholder": "​",
            "style": "IPY_MODEL_0dcea01df4cb4aad91e302c048eb2845",
            "value": "Fetching 2 files: 100%"
          }
        },
        "7bc3b8b86ca54eb59f66ae94d23fa186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843d61e57c4e438698bbcf8d098d9c4c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfafecfac5e945018831a3db1b4b54ef",
            "value": 2
          }
        },
        "0a03827db76446bfb36bc70849803340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2794ca5bfae248a6883244d7a05f129e",
            "placeholder": "​",
            "style": "IPY_MODEL_4e5b66dcd1a04f48a91fd0bd69939f79",
            "value": " 2/2 [00:00&lt;00:00, 187.13it/s]"
          }
        },
        "613ec92d95344923bd7242d8ad903360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a84961a1d694c8597ddb6dbe0dddb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dcea01df4cb4aad91e302c048eb2845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843d61e57c4e438698bbcf8d098d9c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfafecfac5e945018831a3db1b4b54ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2794ca5bfae248a6883244d7a05f129e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5b66dcd1a04f48a91fd0bd69939f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad87547896fa422d8699767127fb9c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b28dd72f04fa454da228b1c54870c18e",
              "IPY_MODEL_de5d988cf5ac448cb29f74217663dcfe",
              "IPY_MODEL_ace026896481437da6f3e572834b055e"
            ],
            "layout": "IPY_MODEL_c84e15acbada401b945d08df08f84f43"
          }
        },
        "b28dd72f04fa454da228b1c54870c18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc7237a9523645529acb3c57da8929f0",
            "placeholder": "​",
            "style": "IPY_MODEL_4b677e79a31649ed81de24432124d5ea",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "de5d988cf5ac448cb29f74217663dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da57cf1e7d9c425493d73bf58980ad67",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7abafd924b554f6da4853828ed496e5a",
            "value": 2
          }
        },
        "ace026896481437da6f3e572834b055e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6062e8fcc9a04cff8806d0aa13cd2753",
            "placeholder": "​",
            "style": "IPY_MODEL_a939024f61834b079716243bf0f9931a",
            "value": " 2/2 [00:35&lt;00:00, 17.70s/it]"
          }
        },
        "c84e15acbada401b945d08df08f84f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7237a9523645529acb3c57da8929f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b677e79a31649ed81de24432124d5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da57cf1e7d9c425493d73bf58980ad67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abafd924b554f6da4853828ed496e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6062e8fcc9a04cff8806d0aa13cd2753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a939024f61834b079716243bf0f9931a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe75fa138974c62800eb87a8acad02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd76f1a15ae4376a17828b202cfa6c1",
              "IPY_MODEL_74f09a78033444a192c4e2510944ef74",
              "IPY_MODEL_af3f2b6c739d494397d785946187d69f"
            ],
            "layout": "IPY_MODEL_41fbf02e76c24ba1b237dce7cb51e78a"
          }
        },
        "ccd76f1a15ae4376a17828b202cfa6c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f15897fbd14d46a09327df42add1b336",
            "placeholder": "​",
            "style": "IPY_MODEL_539e2135618d464caf4f74efa7e517c3",
            "value": "Fetching 2 files: 100%"
          }
        },
        "74f09a78033444a192c4e2510944ef74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac76ff82d8984675b22b73dc3e72d1c4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f105143f911e4fba8faeb15956a20a30",
            "value": 2
          }
        },
        "af3f2b6c739d494397d785946187d69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857555bd08ef452fb25418d7989cadf4",
            "placeholder": "​",
            "style": "IPY_MODEL_f4c16f4ce0b64ffeabaff5e25cf53bca",
            "value": " 2/2 [00:00&lt;00:00, 156.60it/s]"
          }
        },
        "41fbf02e76c24ba1b237dce7cb51e78a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15897fbd14d46a09327df42add1b336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539e2135618d464caf4f74efa7e517c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac76ff82d8984675b22b73dc3e72d1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f105143f911e4fba8faeb15956a20a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "857555bd08ef452fb25418d7989cadf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c16f4ce0b64ffeabaff5e25cf53bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ecfeae66260498fab8a3d301ae1aec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea86e13cceba417594a6b02d12b8712a",
              "IPY_MODEL_f2deb49b7e8a44c3bdad90aa6710a2c5",
              "IPY_MODEL_7ae06a43c85040f2a27f9e96e0b0b07e"
            ],
            "layout": "IPY_MODEL_bc1e918728d4405ba02355a669fc33a0"
          }
        },
        "ea86e13cceba417594a6b02d12b8712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127afd21aafe4187a6579ecee69f1497",
            "placeholder": "​",
            "style": "IPY_MODEL_513cb3ef0c5f4d038d08d4d20bb10242",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f2deb49b7e8a44c3bdad90aa6710a2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce8d2dde705946dfa5cf2b9c5b8c34c9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e4a035b222b406faeb30c9519f73c99",
            "value": 2
          }
        },
        "7ae06a43c85040f2a27f9e96e0b0b07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_780f41dd05244ded9977b203b4981907",
            "placeholder": "​",
            "style": "IPY_MODEL_6bacb2def2ca40d58dd6acff802310f9",
            "value": " 2/2 [00:25&lt;00:00, 11.54s/it]"
          }
        },
        "bc1e918728d4405ba02355a669fc33a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127afd21aafe4187a6579ecee69f1497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513cb3ef0c5f4d038d08d4d20bb10242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8d2dde705946dfa5cf2b9c5b8c34c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4a035b222b406faeb30c9519f73c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "780f41dd05244ded9977b203b4981907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bacb2def2ca40d58dd6acff802310f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0rT1ktpPgGK",
        "outputId": "a1740669-a95b-4277-e104-01b5dcb41ee8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLUEfeV6PyLK",
        "outputId": "731a5ca3-0676-4e86-bbc1-70b35254b723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "GEVWU9qrUnTt",
        "outputId": "ed9556f3-8b61-4467-b8f2-6ef8ab55a885"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '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' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7e1298bc9d6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhf_FAWIKTAWqNpdDUyuACipOqvqRniwXbBSEr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name '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' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "import gc\n",
        "\n",
        "# First, let's optimize Colab's memory usage\n",
        "def clear_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Login to Hugging Face (make sure to replace with your token)\n",
        "def hf_login(token):\n",
        "    try:\n",
        "        login(token=token, add_to_git_credential=True)\n",
        "        print(\"Successfully logged in to Hugging Face!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Login failed. Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example usage (replace with your actual token)\n",
        "if __name__ == \"__main__\":\n",
        "    hf_token = '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'\n",
        "    login_result = hf_login(hf_token)\n",
        "\n",
        "class GRPOConfig:\n",
        "    \"\"\"Configuration optimized for Colab T4 GPU\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        planning_steps: int = 2,  # Reduced from 3 to save memory\n",
        "        critic_lr: float = 3e-5,  # Slightly lower learning rate\n",
        "        reward_scale: float = 0.1,\n",
        "        value_loss_coef: float = 0.5,\n",
        "        entropy_coef: float = 0.01,\n",
        "        max_grad_norm: float = 1.0,\n",
        "        ref_kl_threshold: float = 0.05,\n",
        "        gradient_checkpointing: bool = True  # Added to save memory\n",
        "    ):\n",
        "        self.planning_steps = planning_steps\n",
        "        self.critic_lr = critic_lr\n",
        "        self.reward_scale = reward_scale\n",
        "        self.value_loss_coef = value_loss_coef\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.ref_kl_threshold = ref_kl_threshold\n",
        "        self.gradient_checkpointing = gradient_checkpointing\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"Dataset with optimized memory usage\"\"\"\n",
        "    def __init__(self, dataset_name: str, tokenizer, max_length: int = 512):  # Reduced max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = []\n",
        "\n",
        "        try:\n",
        "            # Load only a subset of the data for Colab\n",
        "            raw_data = load_dataset(dataset_name, split='train[:20%]')  # Only 20% of data\n",
        "\n",
        "            for item in raw_data:\n",
        "                if \"chosen\" in item:\n",
        "                    text = item[\"chosen\"]\n",
        "                    if \"\\n\\nHuman: \" in text and \"\\n\\nAssistant: \" in text:\n",
        "                        parts = text.split(\"\\n\\nAssistant: \")\n",
        "                        prompt = parts[0].replace(\"\\n\\nHuman: \", \"\").strip()\n",
        "                        completion = parts[1].strip()\n",
        "                        self.data.append({\n",
        "                            \"prompt\": prompt,\n",
        "                            \"completion\": completion,\n",
        "                            \"reward\": item.get(\"reward\", 1.0)\n",
        "                        })\n",
        "\n",
        "            if len(self.data) == 0:\n",
        "                raise ValueError(f\"No valid data found in dataset {dataset_name}\")\n",
        "\n",
        "            print(f\"Loaded {len(self.data)} examples from {dataset_name} (subset for Colab)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset {dataset_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        prompt = item[\"prompt\"]\n",
        "        completion = item[\"completion\"]\n",
        "        reward = item[\"reward\"]\n",
        "\n",
        "        text = f\"User: {prompt}\\n\\nAssistant: {completion}\"\n",
        "\n",
        "        encodings = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        labels = encodings[\"input_ids\"].clone()\n",
        "        assistant_start = text.find(\"Assistant: \")\n",
        "        if assistant_start != -1:\n",
        "            assistant_tokens = self.tokenizer(text[:assistant_start], return_tensors=\"pt\")\n",
        "            assistant_token_len = assistant_tokens[\"input_ids\"].shape[1]\n",
        "            labels[0, :assistant_token_len] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels.squeeze(),\n",
        "            \"reward\": torch.tensor(reward, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "class ValueHead(nn.Module):\n",
        "    \"\"\"Simplified value head for memory efficiency\"\"\"\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.value_head = nn.Linear(hidden_size, 1)  # Simplified architecture\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        return self.value_head(hidden_states)\n",
        "\n",
        "class GRPOTrainer:\n",
        "    \"\"\"Trainer optimized for Colab T4 GPU\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"google/gemma-3-4b-it\",\n",
        "        dataset: Dataset = None,\n",
        "        output_dir: str = \"./gemini3-grpo\",\n",
        "        config: GRPOConfig = None,\n",
        "        learning_rate: float = 1e-5,  # Lower learning rate\n",
        "        batch_size: int = 2,  # Reduced batch size\n",
        "        epochs: int = 2,  # Fewer epochs\n",
        "        gradient_accumulation_steps: int = 4,  # Reduced accumulation steps\n",
        "        max_grad_norm: float = 1.0,\n",
        "        warmup_steps: int = 50,  # Reduced warmup\n",
        "        save_steps: int = 200,  # More frequent saves\n",
        "        device: str = None,\n",
        "        mixed_precision: bool = True  # Added mixed precision\n",
        "    ):\n",
        "        self.model_name = model_name\n",
        "        self.dataset = dataset\n",
        "        self.output_dir = output_dir\n",
        "        self.config = config if config else GRPOConfig()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.save_steps = save_steps\n",
        "        self.mixed_precision = mixed_precision\n",
        "\n",
        "        self.device = torch.device(device if device else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Enable TF32 for faster computations (on supported GPUs)\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        self.dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load model with optimizations\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.bfloat16 if self.mixed_precision else torch.float32,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        if self.config.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        # Smaller LoRA config for Colab\n",
        "        lora_config = LoraConfig(\n",
        "            task_type=\"CAUSAL_LM\",\n",
        "            r=8,  # Reduced from 16\n",
        "            lora_alpha=16,  # Reduced from 32\n",
        "            target_modules=[\"q_proj\", \"v_proj\"],  # Fewer target modules\n",
        "            lora_dropout=0.05\n",
        "        )\n",
        "        self.model = get_peft_model(self.model, lora_config)\n",
        "        self.model.print_trainable_parameters()\n",
        "\n",
        "        self.value_head = ValueHead(self.model.config.hidden_size).to(self.device)\n",
        "\n",
        "        # Reference model with same optimizations\n",
        "        self.ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.bfloat16 if self.mixed_precision else torch.float32,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        for param in self.ref_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Optimizers with weight decay\n",
        "        self.optimizer = optim.AdamW(\n",
        "            list(self.model.parameters()) + list(self.value_head.parameters()),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "\n",
        "        self.critic_optimizer = optim.AdamW(\n",
        "            self.value_head.parameters(),\n",
        "            lr=self.config.critic_lr,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "\n",
        "        # Scaler for mixed precision\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)\n",
        "\n",
        "    def kl_divergence(self, logits_a, logits_b, attention_mask):\n",
        "        logits_a = logits_a.view(-1, logits_a.size(-1))\n",
        "        logits_b = logits_b.view(-1, logits_b.size(-1))\n",
        "        attention_mask = attention_mask.view(-1)\n",
        "\n",
        "        mask = attention_mask.bool()\n",
        "        logits_a = logits_a[mask]\n",
        "        logits_b = logits_b[mask]\n",
        "\n",
        "        probs_a = torch.softmax(logits_a, dim=-1)\n",
        "        probs_b = torch.softmax(logits_b, dim=-1)\n",
        "\n",
        "        kl = torch.sum(probs_a * (torch.log(probs_a) - torch.log(probs_b + 1e-10)), dim=-1)\n",
        "        return kl.mean()\n",
        "\n",
        "    def train(self):\n",
        "        print(f\"Starting training on {self.device}\")\n",
        "        self.model.train()\n",
        "        self.value_head.train()\n",
        "\n",
        "        total_steps = 0\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            epoch_loss = 0.0\n",
        "            epoch_policy_loss = 0.0\n",
        "            epoch_value_loss = 0.0\n",
        "            epoch_entropy = 0.0\n",
        "            epoch_kl = 0.0\n",
        "\n",
        "            progress_bar = tqdm(self.dataloader, desc=f\"Epoch {epoch+1}/{self.epochs}\")\n",
        "\n",
        "            for batch_idx, batch in enumerate(progress_bar):\n",
        "                # Move batch to the correct device\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "                total_loss = 0.0\n",
        "\n",
        "                # Forward pass with mixed precision\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=self.mixed_precision):\n",
        "                    with torch.no_grad():\n",
        "                        ref_outputs = self.ref_model(\n",
        "                            input_ids=batch[\"input_ids\"],\n",
        "                            attention_mask=batch[\"attention_mask\"],\n",
        "                            output_hidden_states=True\n",
        "                        )\n",
        "                        ref_logits = ref_outputs.logits\n",
        "                        ref_hidden = ref_outputs.hidden_states[-1]\n",
        "\n",
        "                    current_policy_logits = ref_logits.detach().clone()\n",
        "\n",
        "                    for step in range(self.config.planning_steps):\n",
        "                        outputs = self.model(\n",
        "                            input_ids=batch[\"input_ids\"],\n",
        "                            attention_mask=batch[\"attention_mask\"],\n",
        "                            output_hidden_states=True\n",
        "                        )\n",
        "                        logits = outputs.logits\n",
        "                        hidden = outputs.hidden_states[-1]\n",
        "\n",
        "                        values = self.value_head(hidden[:, -1, :]).squeeze(-1)\n",
        "                        kl = self.kl_divergence(logits, ref_logits, batch[\"attention_mask\"])\n",
        "\n",
        "                        probs = torch.softmax(logits.view(-1, logits.size(-1)), dim=-1)\n",
        "                        entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=-1).mean()\n",
        "\n",
        "                        advantages = batch[\"reward\"] - values.detach()\n",
        "                        policy_loss = -advantages * entropy\n",
        "                        value_loss = 0.5 * ((values - batch[\"reward\"]) ** 2).mean()\n",
        "\n",
        "                        loss = (\n",
        "                            policy_loss\n",
        "                            + self.config.value_loss_coef * value_loss\n",
        "                            - self.config.entropy_coef * entropy\n",
        "                        )\n",
        "\n",
        "                        if kl > self.config.ref_kl_threshold:\n",
        "                            loss += kl\n",
        "\n",
        "                        loss = loss / self.gradient_accumulation_steps\n",
        "                        total_loss += loss.item()\n",
        "\n",
        "                        # Scale loss for mixed precision\n",
        "                        self.scaler.scale(loss).backward()\n",
        "\n",
        "                        epoch_policy_loss += policy_loss.item()\n",
        "                        epoch_value_loss += value_loss.item()\n",
        "                        epoch_entropy += entropy.item()\n",
        "                        epoch_kl += kl.item()\n",
        "\n",
        "                        current_policy_logits = logits.detach()\n",
        "\n",
        "                # Gradient accumulation and update\n",
        "                if (batch_idx + 1) % self.gradient_accumulation_steps == 0:\n",
        "                    # Unscale gradients before clipping\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(\n",
        "                        list(self.model.parameters()) + list(self.value_head.parameters()),\n",
        "                        self.max_grad_norm\n",
        "                    )\n",
        "\n",
        "                    # Step with scaler\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "                    # Clear memory\n",
        "                    clear_memory()\n",
        "\n",
        "                    progress_bar.set_postfix({\n",
        "                        \"loss\": total_loss,\n",
        "                        \"policy_loss\": epoch_policy_loss / (batch_idx + 1),\n",
        "                        \"value_loss\": epoch_value_loss / (batch_idx + 1),\n",
        "                        \"kl\": epoch_kl / (batch_idx + 1)\n",
        "                    })\n",
        "\n",
        "                    total_steps += 1\n",
        "\n",
        "                    # Save checkpoint more frequently\n",
        "                    if total_steps % self.save_steps == 0:\n",
        "                        current_loss = total_loss / (batch_idx + 1)\n",
        "                        if current_loss < best_loss:\n",
        "                            best_loss = current_loss\n",
        "                            self.save_checkpoint(f\"checkpoint-best\")\n",
        "                        self.save_checkpoint(f\"checkpoint-step-{total_steps}\")\n",
        "\n",
        "            # Save after each epoch\n",
        "            self.save_checkpoint(f\"checkpoint-epoch-{epoch+1}\")\n",
        "\n",
        "            print(f\"Epoch {epoch+1} stats:\")\n",
        "            print(f\"  Policy loss: {epoch_policy_loss / len(self.dataloader):.4f}\")\n",
        "            print(f\"  Value loss: {epoch_value_loss / len(self.dataloader):.4f}\")\n",
        "            print(f\"  Entropy: {epoch_entropy / len(self.dataloader):.4f}\")\n",
        "            print(f\"  KL: {epoch_kl / len(self.dataloader):.4f}\")\n",
        "\n",
        "        self.save_checkpoint(\"final-model\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "    def save_checkpoint(self, checkpoint_name: str):\n",
        "        checkpoint_dir = os.path.join(self.output_dir, checkpoint_name)\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        # Save with safetensors for efficiency\n",
        "        self.model.save_pretrained(checkpoint_dir, safe_serialization=True)\n",
        "        self.tokenizer.save_pretrained(checkpoint_dir)\n",
        "        torch.save(self.value_head.state_dict(), os.path.join(checkpoint_dir, \"value_head.pt\"))\n",
        "        torch.save(self.optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
        "\n",
        "        print(f\"Saved checkpoint to {checkpoint_dir}\")\n",
        "\n",
        "def main():\n",
        "    # Colab-optimized parameters\n",
        "    model_name = \"google/gemma-3-4b-it\"\n",
        "    dataset_name = \"Anthropic/hh-rlhf\"\n",
        "    output_dir = \"./gemini3-grpo\"\n",
        "    learning_rate = 1e-5\n",
        "    batch_size = 2\n",
        "    epochs = 2\n",
        "    gradient_accumulation_steps = 4\n",
        "    planning_steps = 2\n",
        "    save_steps = 200\n",
        "\n",
        "    # Clear memory before starting\n",
        "    clear_memory()\n",
        "\n",
        "    # Configuration with Colab optimizations\n",
        "    grpo_config = GRPOConfig(\n",
        "        planning_steps=planning_steps,\n",
        "        gradient_checkpointing=True\n",
        "    )\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    try:\n",
        "        # Load smaller dataset\n",
        "        dataset = CustomDataset(dataset_name, tokenizer, max_length=512)\n",
        "        print(f\"Dataset successfully created with {len(dataset)} samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Initialize trainer with Colab-optimized settings\n",
        "    trainer = GRPOTrainer(\n",
        "        model_name=model_name,\n",
        "        dataset=dataset,\n",
        "        output_dir=output_dir,\n",
        "        config=grpo_config,\n",
        "        learning_rate=learning_rate,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        save_steps=save_steps,\n",
        "        mixed_precision=True\n",
        "    )\n",
        "\n",
        "    # Train with memory monitoring\n",
        "    print(\"Starting training...\")\n",
        "    print(f\"Free memory: {torch.cuda.mem_get_info()[0]/1024**2:.2f} MB free\")\n",
        "    trainer.train()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886,
          "referenced_widgets": [
            "766fedca6b4b4e7184ce9ce192eb653d",
            "3d8ab1b8ce6c49578f1fed99b92c9db1",
            "8a85258aee9340e59c2c85fa56fe35da",
            "800782a9209c4b1ab8b9b6ff83004138",
            "63659db7558044dbbf84d67c92a71f56",
            "c2e93ac871b34fdba871f7d4999a3109",
            "2ab3687fceef4406aaa5d1f6fde266da",
            "88c518209bff49758db5755a71920b63",
            "080563fa493b4156a0d015d2c39dac02",
            "fd52bcb5b02d482ca90cff90a15f512f",
            "2330899f0d6b4dc2b685b22a85b46893",
            "b901ba7bf4e34ef2bfe40aa0d9acf3f2",
            "64876cba3c7a4e118501a937a667da06",
            "af64ce1d2b2349be9485c5b6b90c3a43",
            "d46c51d2360344978f2b3240a14aa2ba",
            "fa396d33890b4570a0fffe23838c70cd",
            "8b70dcc0f18d441ab310fc2d22a402f9",
            "a02b009722d74b2b97623008d798a72b",
            "adbb4dd5cd654f75a04b28f834d94405",
            "399988f4b67b4cb08f8518be01865269",
            "b8b9eac714044a89b1e0f1402b0943fb",
            "47165f1bca024a02ba5e197ec2b848c0",
            "2f126918abe94475b17482f5979c151e",
            "5de759dd94a949d5b4de0fa4e318b7f8",
            "e7a7145f47ae48489f4ea0281fd8370d",
            "c7657116946b4feab964896704523ad6",
            "5a5077c05612429d9e900f932d4ca9ed",
            "b03aa0a1c8fe4dfbb1da56ba3c8ca620",
            "196f450b6ae44690b6650a1cb7651279",
            "52b0a692a272458b9f36f195f69e8efa",
            "268ed8209ce04c199db8f16ca439090a",
            "aebc34c41e71481cbbfe53f22d53da9e",
            "dabe169814364576b871babea2285fcd",
            "baf6c3d7c9ae4e13a8c1b8a74c9bef62",
            "1a2821ef8d8543efa9459f3c1c09017d",
            "96671afcb6f740c4be322560ae65d6d7",
            "2da7dc119d9a426793bf040c6b691270",
            "96a4427cfaf34cf3930bbc2e0dfc43eb",
            "dfc96d16c5d14bf494f02c6610cf5d4b",
            "2c29df1d62a0448e9f544364bef0087f",
            "e55cf9024f5f4874977b2124d47f81c8",
            "c56f9532299b4cdcb990dc93ee046958",
            "0a356641c274412bb455dbc82f82f1fc",
            "2ace1e39a8f54648bd0091c5377c9a82"
          ]
        },
        "id": "xeFeSMBAUnZw",
        "outputId": "5d79ecb8-f171-4281-c005-00860df4b047"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login failed. Error: name 'login' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 32160 examples from Anthropic/hh-rlhf (subset for Colab)\n",
            "Dataset successfully created with 32160 samples\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "766fedca6b4b4e7184ce9ce192eb653d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b901ba7bf4e34ef2bfe40aa0d9acf3f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,228,224 || all params: 3,882,491,392 || trainable%: 0.0574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f126918abe94475b17482f5979c151e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baf6c3d7c9ae4e13a8c1b8a74c9bef62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "<ipython-input-4-b6828cf675da>:222: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Free memory: 314.12 MB free\n",
            "Starting training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:   0%|          | 0/16080 [00:00<?, ?it/s]It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "Epoch 1/2:   0%|          | 0/16080 [00:16<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 296.12 MiB is free. Process 116454 has 14.45 GiB memory in use. Of the allocated memory 14.03 GiB is allocated by PyTorch, and 305.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b6828cf675da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-b6828cf675da>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Free memory: {torch.cuda.mem_get_info()[0]/1024**2:.2f} MB free\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b6828cf675da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                         outputs = self.model(\n\u001b[0m\u001b[1;32m    276\u001b[0m                             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0mslice_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlogits_to_keep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logit_softcapping\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logit_softcapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 514.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 296.12 MiB is free. Process 116454 has 14.45 GiB memory in use. Of the allocated memory 14.03 GiB is allocated by PyTorch, and 305.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "import gc\n",
        "\n",
        "# Set environment variable to manage memory fragmentation\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# First, let's optimize Colab's memory usage\n",
        "def clear_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Login to Hugging Face (make sure to replace with your token)\n",
        "def hf_login(token):\n",
        "    try:\n",
        "        login(token=token, add_to_git_credential=True)\n",
        "        print(\"Successfully logged in to Hugging Face!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Login failed. Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example usage (replace with your actual token)\n",
        "if __name__ == \"__main__\":\n",
        "    hf_token = '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'\n",
        "    login_result = hf_login(hf_token)\n",
        "\n",
        "class GRPOConfig:\n",
        "    \"\"\"Configuration optimized for Colab T4 GPU\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        planning_steps: int = 2,  # Reduced from 3 to save memory\n",
        "        critic_lr: float = 3e-5,  # Slightly lower learning rate\n",
        "        reward_scale: float = 0.1,\n",
        "        value_loss_coef: float = 0.5,\n",
        "        entropy_coef: float = 0.01,\n",
        "        max_grad_norm: float = 1.0,\n",
        "        ref_kl_threshold: float = 0.05,\n",
        "        gradient_checkpointing: bool = True  # Added to save memory\n",
        "    ):\n",
        "        self.planning_steps = planning_steps\n",
        "        self.critic_lr = critic_lr\n",
        "        self.reward_scale = reward_scale\n",
        "        self.value_loss_coef = value_loss_coef\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.ref_kl_threshold = ref_kl_threshold\n",
        "        self.gradient_checkpointing = gradient_checkpointing\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    \"\"\"Dataset with optimized memory usage\"\"\"\n",
        "    def __init__(self, dataset_name: str, tokenizer, max_length: int = 512):  # Reduced max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = []\n",
        "\n",
        "        try:\n",
        "            # Load only a subset of the data for Colab\n",
        "            raw_data = load_dataset(dataset_name, split='train[:20%]')  # Only 20% of data\n",
        "\n",
        "            for item in raw_data:\n",
        "                if \"chosen\" in item:\n",
        "                    text = item[\"chosen\"]\n",
        "                    if \"\\n\\nHuman: \" in text and \"\\n\\nAssistant: \" in text:\n",
        "                        parts = text.split(\"\\n\\nAssistant: \")\n",
        "                        prompt = parts[0].replace(\"\\n\\nHuman: \", \"\").strip()\n",
        "                        completion = parts[1].strip()\n",
        "                        self.data.append({\n",
        "                            \"prompt\": prompt,\n",
        "                            \"completion\": completion,\n",
        "                            \"reward\": item.get(\"reward\", 1.0)\n",
        "                        })\n",
        "\n",
        "            if len(self.data) == 0:\n",
        "                raise ValueError(f\"No valid data found in dataset {dataset_name}\")\n",
        "\n",
        "            print(f\"Loaded {len(self.data)} examples from {dataset_name} (subset for Colab)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset {dataset_name}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        prompt = item[\"prompt\"]\n",
        "        completion = item[\"completion\"]\n",
        "        reward = item[\"reward\"]\n",
        "\n",
        "        text = f\"User: {prompt}\\n\\nAssistant: {completion}\"\n",
        "\n",
        "        encodings = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        labels = encodings[\"input_ids\"].clone()\n",
        "        assistant_start = text.find(\"Assistant: \")\n",
        "        if assistant_start != -1:\n",
        "            assistant_tokens = self.tokenizer(text[:assistant_start], return_tensors=\"pt\")\n",
        "            assistant_token_len = assistant_tokens[\"input_ids\"].shape[1]\n",
        "            labels[0, :assistant_token_len] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels.squeeze(),\n",
        "            \"reward\": torch.tensor(reward, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "class ValueHead(nn.Module):\n",
        "    \"\"\"Simplified value head for memory efficiency\"\"\"\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.value_head = nn.Linear(hidden_size, 1)  # Simplified architecture\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        return self.value_head(hidden_states)\n",
        "\n",
        "class GRPOTrainer:\n",
        "    \"\"\"Trainer optimized for Colab T4 GPU\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_name: str = \"google/gemma-3-4b-it\",\n",
        "        dataset: Dataset = None,\n",
        "        output_dir: str = \"./gemini3-grpo\",\n",
        "        config: GRPOConfig = None,\n",
        "        learning_rate: float = 1e-5,  # Lower learning rate\n",
        "        batch_size: int = 2,  # Reduced batch size\n",
        "        epochs: int = 2,  # Fewer epochs\n",
        "        gradient_accumulation_steps: int = 8,  # Increased accumulation steps\n",
        "        max_grad_norm: float = 1.0,\n",
        "        warmup_steps: int = 50,  # Reduced warmup\n",
        "        save_steps: int = 200,  # More frequent saves\n",
        "        device: str = None,\n",
        "        mixed_precision: bool = True  # Added mixed precision\n",
        "    ):\n",
        "        self.model_name = model_name\n",
        "        self.dataset = dataset\n",
        "        self.output_dir = output_dir\n",
        "        self.config = config if config else GRPOConfig()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.save_steps = save_steps\n",
        "        self.mixed_precision = mixed_precision\n",
        "\n",
        "        self.device = torch.device(device if device else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Enable TF32 for faster computations (on supported GPUs)\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        self.dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load model with optimizations\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.bfloat16 if self.mixed_precision else torch.float32,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        if self.config.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        # Smaller LoRA config for Colab\n",
        "        lora_config = LoraConfig(\n",
        "            task_type=\"CAUSAL_LM\",\n",
        "            r=8,  # Reduced from 16\n",
        "            lora_alpha=16,  # Reduced from 32\n",
        "            target_modules=[\"q_proj\", \"v_proj\"],  # Fewer target modules\n",
        "            lora_dropout=0.05\n",
        "        )\n",
        "        self.model = get_peft_model(self.model, lora_config)\n",
        "        self.model.print_trainable_parameters()\n",
        "\n",
        "        self.value_head = ValueHead(self.model.config.hidden_size).to(self.device)\n",
        "\n",
        "        # Reference model with same optimizations\n",
        "        self.ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.bfloat16 if self.mixed_precision else torch.float32,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        for param in self.ref_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Optimizers with weight decay\n",
        "        self.optimizer = optim.AdamW(\n",
        "            list(self.model.parameters()) + list(self.value_head.parameters()),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "\n",
        "        self.critic_optimizer = optim.AdamW(\n",
        "            self.value_head.parameters(),\n",
        "            lr=self.config.critic_lr,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "\n",
        "        # Scaler for mixed precision\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)\n",
        "\n",
        "    def kl_divergence(self, logits_a, logits_b, attention_mask):\n",
        "        logits_a = logits_a.view(-1, logits_a.size(-1))\n",
        "        logits_b = logits_b.view(-1, logits_b.size(-1))\n",
        "        attention_mask = attention_mask.view(-1)\n",
        "\n",
        "        mask = attention_mask.bool()\n",
        "        logits_a = logits_a[mask]\n",
        "        logits_b = logits_b[mask]\n",
        "\n",
        "        probs_a = torch.softmax(logits_a, dim=-1)\n",
        "        probs_b = torch.softmax(logits_b, dim=-1)\n",
        "\n",
        "        kl = torch.sum(probs_a * (torch.log(probs_a) - torch.log(probs_b + 1e-10)), dim=-1)\n",
        "        return kl.mean()\n",
        "\n",
        "    def train(self):\n",
        "        print(f\"Starting training on {self.device}\")\n",
        "        self.model.train()\n",
        "        self.value_head.train()\n",
        "\n",
        "        total_steps = 0\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            epoch_loss = 0.0\n",
        "            epoch_policy_loss = 0.0\n",
        "            epoch_value_loss = 0.0\n",
        "            epoch_entropy = 0.0\n",
        "            epoch_kl = 0.0\n",
        "\n",
        "            progress_bar = tqdm(self.dataloader, desc=f\"Epoch {epoch+1}/{self.epochs}\")\n",
        "\n",
        "            for batch_idx, batch in enumerate(progress_bar):\n",
        "                # Move batch to the correct device\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "                total_loss = 0.0\n",
        "\n",
        "                # Forward pass with mixed precision\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=self.mixed_precision):\n",
        "                    with torch.no_grad():\n",
        "                        ref_outputs = self.ref_model(\n",
        "                            input_ids=batch[\"input_ids\"],\n",
        "                            attention_mask=batch[\"attention_mask\"],\n",
        "                            output_hidden_states=True\n",
        "                        )\n",
        "                        ref_logits = ref_outputs.logits\n",
        "                        ref_hidden = ref_outputs.hidden_states[-1]\n",
        "\n",
        "                    current_policy_logits = ref_logits.detach().clone()\n",
        "\n",
        "                    for step in range(self.config.planning_steps):\n",
        "                        outputs = self.model(\n",
        "                            input_ids=batch[\"input_ids\"],\n",
        "                            attention_mask=batch[\"attention_mask\"],\n",
        "                            output_hidden_states=True\n",
        "                        )\n",
        "                        logits = outputs.logits\n",
        "                        hidden = outputs.hidden_states[-1]\n",
        "\n",
        "                        values = self.value_head(hidden[:, -1, :]).squeeze(-1)\n",
        "                        kl = self.kl_divergence(logits, ref_logits, batch[\"attention_mask\"])\n",
        "\n",
        "                        probs = torch.softmax(logits.view(-1, logits.size(-1)), dim=-1)\n",
        "                        entropy = -torch.sum(probs * torch.log(probs + 1e-10), dim=-1).mean()\n",
        "\n",
        "                        advantages = batch[\"reward\"] - values.detach()\n",
        "                        policy_loss = -advantages * entropy\n",
        "                        value_loss = 0.5 * ((values - batch[\"reward\"]) ** 2).mean()\n",
        "\n",
        "                        loss = (\n",
        "                            policy_loss\n",
        "                            + self.config.value_loss_coef * value_loss\n",
        "                            - self.config.entropy_coef * entropy\n",
        "                        )\n",
        "\n",
        "                        if kl > self.config.ref_kl_threshold:\n",
        "                            loss += kl\n",
        "\n",
        "                        loss = loss / self.gradient_accumulation_steps\n",
        "                        total_loss += loss.item()\n",
        "\n",
        "                        # Scale loss for mixed precision\n",
        "                        self.scaler.scale(loss).backward()\n",
        "\n",
        "                        epoch_policy_loss += policy_loss.item()\n",
        "                        epoch_value_loss += value_loss.item()\n",
        "                        epoch_entropy += entropy.item()\n",
        "                        epoch_kl += kl.item()\n",
        "\n",
        "                        current_policy_logits = logits.detach()\n",
        "\n",
        "                # Gradient accumulation and update\n",
        "                if (batch_idx + 1) % self.gradient_accumulation_steps == 0:\n",
        "                    # Unscale gradients before clipping\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(\n",
        "                        list(self.model.parameters()) + list(self.value_head.parameters()),\n",
        "                        self.max_grad_norm\n",
        "                    )\n",
        "\n",
        "                    # Step with scaler\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                    self.optimizer.zero_grad()\n",
        "\n",
        "                    # Clear memory\n",
        "                    clear_memory()\n",
        "\n",
        "                    progress_bar.set_postfix({\n",
        "                        \"loss\": total_loss,\n",
        "                        \"policy_loss\": epoch_policy_loss / (batch_idx + 1),\n",
        "                        \"value_loss\": epoch_value_loss / (batch_idx + 1),\n",
        "                        \"kl\": epoch_kl / (batch_idx + 1)\n",
        "                    })\n",
        "\n",
        "                    total_steps += 1\n",
        "\n",
        "                    # Save checkpoint more frequently\n",
        "                    if total_steps % self.save_steps == 0:\n",
        "                        current_loss = total_loss / (batch_idx + 1)\n",
        "                        if current_loss < best_loss:\n",
        "                            best_loss = current_loss\n",
        "                            self.save_checkpoint(f\"checkpoint-best\")\n",
        "                        self.save_checkpoint(f\"checkpoint-step-{total_steps}\")\n",
        "\n",
        "            # Save after each epoch\n",
        "            self.save_checkpoint(f\"checkpoint-epoch-{epoch+1}\")\n",
        "\n",
        "            print(f\"Epoch {epoch+1} stats:\")\n",
        "            print(f\"  Policy loss: {epoch_policy_loss / len(self.dataloader):.4f}\")\n",
        "            print(f\"  Value loss: {epoch_value_loss / len(self.dataloader):.4f}\")\n",
        "            print(f\"  Entropy: {epoch_entropy / len(self.dataloader):.4f}\")\n",
        "            print(f\"  KL: {epoch_kl / len(self.dataloader):.4f}\")\n",
        "\n",
        "        self.save_checkpoint(\"final-model\")\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "    def save_checkpoint(self, checkpoint_name: str):\n",
        "        checkpoint_dir = os.path.join(self.output_dir, checkpoint_name)\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        # Save with safetensors for efficiency\n",
        "        self.model.save_pretrained(checkpoint_dir, safe_serialization=True)\n",
        "        self.tokenizer.save_pretrained(checkpoint_dir)\n",
        "        torch.save(self.value_head.state_dict(), os.path.join(checkpoint_dir, \"value_head.pt\"))\n",
        "        torch.save(self.optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
        "\n",
        "        print(f\"Saved checkpoint to {checkpoint_dir}\")\n",
        "\n",
        "def main():\n",
        "    # Colab-optimized parameters\n",
        "    model_name = \"google/gemma-3-4b-it\"\n",
        "    dataset_name = \"Anthropic/hh-rlhf\"\n",
        "    output_dir = \"./gemini3-grpo\"\n",
        "    learning_rate = 1e-5\n",
        "    batch_size = 2\n",
        "    epochs = 2\n",
        "    gradient_accumulation_steps = 8\n",
        "    planning_steps = 2\n",
        "    save_steps = 200\n",
        "\n",
        "    # Clear memory before starting\n",
        "    clear_memory()\n",
        "\n",
        "    # Configuration with Colab optimizations\n",
        "    grpo_config = GRPOConfig(\n",
        "        planning_steps=planning_steps,\n",
        "        gradient_checkpointing=True\n",
        "    )\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    try:\n",
        "        # Load smaller dataset\n",
        "        dataset = CustomDataset(dataset_name, tokenizer, max_length=512)\n",
        "        print(f\"Dataset successfully created with {len(dataset)} samples\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create dataset: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Initialize trainer with Colab-optimized settings\n",
        "    trainer = GRPOTrainer(\n",
        "        model_name=model_name,\n",
        "        dataset=dataset,\n",
        "        output_dir=output_dir,\n",
        "        config=grpo_config,\n",
        "        learning_rate=learning_rate,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        save_steps=save_steps,\n",
        "        mixed_precision=True\n",
        "    )\n",
        "\n",
        "    # Train with memory monitoring\n",
        "    print(\"Starting training...\")\n",
        "    print(f\"Free memory: {torch.cuda.mem_get_info()[0]/1024**2:.2f} MB free\")\n",
        "    trainer.train()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886,
          "referenced_widgets": [
            "1dd9487d0509414a9557c94315066299",
            "4f87e5eac4fc475489c7bc3f2ac8a930",
            "7bc3b8b86ca54eb59f66ae94d23fa186",
            "0a03827db76446bfb36bc70849803340",
            "613ec92d95344923bd7242d8ad903360",
            "8a84961a1d694c8597ddb6dbe0dddb89",
            "0dcea01df4cb4aad91e302c048eb2845",
            "843d61e57c4e438698bbcf8d098d9c4c",
            "bfafecfac5e945018831a3db1b4b54ef",
            "2794ca5bfae248a6883244d7a05f129e",
            "4e5b66dcd1a04f48a91fd0bd69939f79",
            "ad87547896fa422d8699767127fb9c74",
            "b28dd72f04fa454da228b1c54870c18e",
            "de5d988cf5ac448cb29f74217663dcfe",
            "ace026896481437da6f3e572834b055e",
            "c84e15acbada401b945d08df08f84f43",
            "cc7237a9523645529acb3c57da8929f0",
            "4b677e79a31649ed81de24432124d5ea",
            "da57cf1e7d9c425493d73bf58980ad67",
            "7abafd924b554f6da4853828ed496e5a",
            "6062e8fcc9a04cff8806d0aa13cd2753",
            "a939024f61834b079716243bf0f9931a",
            "fbe75fa138974c62800eb87a8acad02d",
            "ccd76f1a15ae4376a17828b202cfa6c1",
            "74f09a78033444a192c4e2510944ef74",
            "af3f2b6c739d494397d785946187d69f",
            "41fbf02e76c24ba1b237dce7cb51e78a",
            "f15897fbd14d46a09327df42add1b336",
            "539e2135618d464caf4f74efa7e517c3",
            "ac76ff82d8984675b22b73dc3e72d1c4",
            "f105143f911e4fba8faeb15956a20a30",
            "857555bd08ef452fb25418d7989cadf4",
            "f4c16f4ce0b64ffeabaff5e25cf53bca",
            "0ecfeae66260498fab8a3d301ae1aec5",
            "ea86e13cceba417594a6b02d12b8712a",
            "f2deb49b7e8a44c3bdad90aa6710a2c5",
            "7ae06a43c85040f2a27f9e96e0b0b07e",
            "bc1e918728d4405ba02355a669fc33a0",
            "127afd21aafe4187a6579ecee69f1497",
            "513cb3ef0c5f4d038d08d4d20bb10242",
            "ce8d2dde705946dfa5cf2b9c5b8c34c9",
            "0e4a035b222b406faeb30c9519f73c99",
            "780f41dd05244ded9977b203b4981907",
            "6bacb2def2ca40d58dd6acff802310f9"
          ]
        },
        "id": "H_QRktRuUnee",
        "outputId": "7cae6d6d-a21d-470b-f165-e8cbef0e8cab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login failed. Error: name 'login' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 32160 examples from Anthropic/hh-rlhf (subset for Colab)\n",
            "Dataset successfully created with 32160 samples\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dd9487d0509414a9557c94315066299"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad87547896fa422d8699767127fb9c74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,228,224 || all params: 3,882,491,392 || trainable%: 0.0574\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe75fa138974c62800eb87a8acad02d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ecfeae66260498fab8a3d301ae1aec5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "<ipython-input-3-1dfa1847a9c9>:225: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.mixed_precision)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Free memory: 2126.12 MB free\n",
            "Starting training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:   0%|          | 0/16080 [00:00<?, ?it/s]It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "Epoch 1/2:   0%|          | 0/16080 [00:18<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 70.12 MiB is free. Process 132112 has 14.67 GiB memory in use. Of the allocated memory 14.53 GiB is allocated by PyTorch, and 18.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1dfa1847a9c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-1dfa1847a9c9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Free memory: {torch.cuda.mem_get_info()[0]/1024**2:.2f} MB free\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1dfa1847a9c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1dfa1847a9c9>\u001b[0m in \u001b[0;36mkl_divergence\u001b[0;34m(self, logits_a, logits_b, attention_mask)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mlogits_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mlogits_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 70.12 MiB is free. Process 132112 has 14.67 GiB memory in use. Of the allocated memory 14.53 GiB is allocated by PyTorch, and 18.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}